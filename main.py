import os
import random
import json
import openai
from aiogram import Bot, Dispatcher, executor, types
from aiogram.contrib.fsm_storage.memory import MemoryStorage

# -----------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# -----------------------------
# –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä—è–º–æ–π –∫–ª—é—á –¥–ª—è —Ç–µ—Å—Ç–∞ –∏–ª–∏ —á–µ—Ä–µ–∑ .env:
openai.api_key = "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"

BOT_TOKEN = "—Ç–≤–æ–π_–±–æ—Ç_—Ç–æ–∫–µ–Ω_–∏–∑_BotFather"

bot = Bot(token=BOT_TOKEN, parse_mode=types.ParseMode.HTML)
dp = Dispatcher(bot, storage=MemoryStorage())

# -----------------------------
# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º—Ç—ã
# -----------------------------
with open("data/prompts.json", "r", encoding="utf-8") as f:
    PROMPTS = json.load(f)

# -----------------------------
# –§—É–Ω–∫—Ü–∏—è –æ–±—â–µ–Ω–∏—è —Å GPT
# -----------------------------
def ai_reply(user_message):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π Telegram-–±–æ—Ç –ø–æ –∏–º–µ–Ω–∏ PromptPilot. –û–±—â–∞–π—Å—è –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫, –∏—Å–ø–æ–ª—å–∑—É–π —é–º–æ—Ä, —Å–º–∞–π–ª—ã –∏ –Ω–µ–º–Ω–æ–≥–æ –∑—É–º–µ—Ä—Å–∫–∏–π —Å—Ç–∏–ª—å."},
            {"role": "user", "content": user_message}
        ]
    )
    return response["choices"][0]["message"]["content"]

# -----------------------------
# –•–µ–Ω–¥–ª–µ—Ä—ã
# -----------------------------
@dp.message_handler(commands=["start"])
async def start_command(message: types.Message):
    text = (
        f"–ô–æ—É, {message.from_user.first_name} üëã\n\n"
        "–Ø —Ç–≤–æ–π –∫–∞—Ä–º–∞–Ω–Ω—ã–π <b>PromptPilot</b> ‚úàÔ∏è\n"
        "–î–∞–≤–∞–π –±–∞—Ö–Ω–µ–º —Ç–µ–±–µ —Å–≤–µ–∂–∏–π –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏? üî•\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "üëâ /prompt ‚Äî —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–º—Ç\n"
        "üëâ /chat ‚Äî –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å–æ –º–Ω–æ–π\n"
        "üëâ /help ‚Äî –ø–æ–º–æ—â—å"
    )
    await message.answer(text)


@dp.message_handler(commands=["prompt"])
async def get_prompt(message: types.Message):
    prompt = random.choice(PROMPTS)
    await message.answer(f"üé® –í–æ—Ç —Ç–µ–±–µ –ø—Ä–æ–º—Ç:\n\n<code>{prompt}</code>")


@dp.message_handler(commands=["help"])
async def help_command(message: types.Message):
    await message.answer(
        "üìñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/prompt ‚Äî –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–º—Ç\n"
        "/chat ‚Äî –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å–æ –º–Ω–æ–π\n"
        "/help ‚Äî –ø–æ–º–æ—â—å"
    )


# –ß–∞—Ç —Å –±–æ—Ç–æ–º
@dp.message_handler(commands=["chat"])
async def chat_mode(message: types.Message):
    await message.answer("–û–∫–µ–π, –±—Ä–æ, –¥–∞–≤–∞–π –ø–æ—Ç—Ä–µ—â–∏–º ü§ü –ü–∏—à–∏ —á—Ç–æ —É–≥–æ–¥–Ω–æ!")


@dp.message_handler(lambda msg: True)
async def casual_chat(message: types.Message):
    if not message.text.startswith("/"):
        try:
            reply = ai_reply(message.text)
            await message.answer(reply)
        except Exception as e:
            # –ù–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–æ–∫ OpenAI API
            await message.answer("–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ üòÖ –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑!")
            print("Error GPT:", e)


# -----------------------------
# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
# -----------------------------
if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
