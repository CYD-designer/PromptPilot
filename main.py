import os
import random
import json
import openai
from aiogram import Bot, Dispatcher, executor, types
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from dotenv import load_dotenv

# -----------------------------
# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
# -----------------------------
load_dotenv()  # —á–∏—Ç–∞–µ–º .env

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not BOT_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–û—à–∏–±–∫–∞: –ø—Ä–æ–≤–µ—Ä—å BOT_TOKEN –∏ OPENAI_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

openai.api_key = OPENAI_API_KEY

# -----------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
# -----------------------------
bot = Bot(token=BOT_TOKEN, parse_mode=types.ParseMode.HTML)
dp = Dispatcher(bot, storage=MemoryStorage())

# -----------------------------
# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º—Ç—ã
# -----------------------------
with open("data/prompts.json", "r", encoding="utf-8") as f:
    PROMPTS = json.load(f)

# -----------------------------
# –§—É–Ω–∫—Ü–∏—è –æ–±—â–µ–Ω–∏—è —Å GPT
# -----------------------------
def ai_reply(user_message):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π Telegram-–±–æ—Ç –ø–æ –∏–º–µ–Ω–∏ PromptPilot. –û–±—â–∞–π—Å—è –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫, –∏—Å–ø–æ–ª—å–∑—É–π —é–º–æ—Ä, —Å–º–∞–π–ª—ã –∏ –Ω–µ–º–Ω–æ–≥–æ –∑—É–º–µ—Ä—Å–∫–∏–π —Å—Ç–∏–ª—å."},
                {"role": "user", "content": user_message}
            ]
        )
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        print("–û—à–∏–±–∫–∞ GPT:", e)
        return "–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ üòÖ –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑!"

# -----------------------------
# –•–µ–Ω–¥–ª–µ—Ä—ã
# -----------------------------
@dp.message_handler(commands=["start"])
async def start_command(message: types.Message):
    text = (
        f"–ô–æ—É, {message.from_user.first_name} üëã\n\n"
        "–Ø —Ç–≤–æ–π –∫–∞—Ä–º–∞–Ω–Ω—ã–π <b>PromptPilot</b> ‚úàÔ∏è\n"
        "–î–∞–≤–∞–π –±–∞—Ö–Ω–µ–º —Ç–µ–±–µ —Å–≤–µ–∂–∏–π –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏? üî•\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "üëâ /prompt ‚Äî —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–º—Ç\n"
        "üëâ /chat ‚Äî –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å–æ –º–Ω–æ–π\n"
        "üëâ /help ‚Äî –ø–æ–º–æ—â—å"
    )
    await message.answer(text)

@dp.message_handler(commands=["prompt"])
async def get_prompt(message: types.Message):
    prompt = random.choice(PROMPTS)
    await message.answer(f"üé® –í–æ—Ç —Ç–µ–±–µ –ø—Ä–æ–º—Ç:\n\n<code>{prompt}</code>")

@dp.message_handler(commands=["help"])
async def help_command(message: types.Message):
    await message.answer(
        "üìñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/prompt ‚Äî –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–º—Ç\n"
        "/chat ‚Äî –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å–æ –º–Ω–æ–π\n"
        "/help ‚Äî –ø–æ–º–æ—â—å"
    )

# –ß–∞—Ç —Å GPT
@dp.message_handler(commands=["chat"])
async def chat_mode(message: types.Message):
    await message.answer("–û–∫–µ–π, –±—Ä–æ, –¥–∞–≤–∞–π –ø–æ—Ç—Ä–µ—â–∏–º ü§ü –ü–∏—à–∏ —á—Ç–æ —É–≥–æ–¥–Ω–æ!")

@dp.message_handler(lambda msg: True)
async def casual_chat(message: types.Message):
    if not message.text.startswith("/"):
        reply = ai_reply(message.text)
        await message.answer(reply)

# -----------------------------
# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
# -----------------------------
if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
